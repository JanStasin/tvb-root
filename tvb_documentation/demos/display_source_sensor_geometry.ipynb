{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING  File 'hemispheres' not found in ZIP.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "from tvb.simulator.plot.head_plotter_3d import HeadPlotter3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display ROIs & M/EEG sensor positions\n",
    "\n",
    "*Candidate for new tutorial on visualizing all elements of the data set*\n",
    "\n",
    "To be sure of the accuracy of forward solution for M/EEG, it is important to verify the geometry of the sources and sensors, as well as the boundaries. Here, we plot these elements of the forward solution for TVB's default dataset.\n",
    "\n",
    "First, we load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp = HeadPlotter3D()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "then, plot the different elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85dbfc4d43fe4eaea7ba3942c6c89663",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "843e5d1409d147aabef75e106b6f785b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Checkbox(value=False, description='Show ROI Centers'), Checkbox(value=False, description='Show …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5bf25bdda2344a29df411c8214f26b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hp.display_source_sensor_geometry()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_More visualizations to come:_\n",
    "\n",
    "* volume data -> MRI acquisition -> Registration -> Coordinates transform to MNI space \n",
    " |\n",
    "  \\-- voxel-based gray matter parcellation (obtain parcellation mask) -> AAL/anatomical template\n",
    " \n",
    "* surfaces data (cortical, skull, skin surfaces extraction) -> FSL/BET \n",
    "\n",
    "* connectivity data (white matter weights, tract-lengths)   -> Diffusion Toolkit + TrackVis\n",
    "\n",
    "* region mapping between parcellation and number of vertices in the cortical surface.\n",
    "\n",
    "+ lead-field matrices (ie, projection matrices) mapping nodes onto EEG/MEG space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
